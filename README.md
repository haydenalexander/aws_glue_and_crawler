# aws_glue_and_crawler

Made a web crawler via AWS, took the contents of the customers.csv, grabbed the orders.csv, and managed to pick up the entire schema which stopped us from manual entry as AWS did the rest in indentifying their data types (int,string).
Used for large datasets.

![image](https://github.com/user-attachments/assets/bce189ff-4481-4ecc-a0d0-cd4a8b1c641e)
